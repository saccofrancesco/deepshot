{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with Optuna Hyperparameter Tuning\n",
    "\n",
    "#### Overview\n",
    "This notebook implements a machine learning pipeline to predict NBA game outcomes using XGBoost with automated hyperparameter optimization via Optuna.\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "##### 1. Data Preparation\n",
    "- Load NBA game dataset from CSV\n",
    "- Filter games from October 19, 2021 onwards\n",
    "- Remove non-predictive features (date, team names)\n",
    "- Separate features (X) and target variable (winning_team)\n",
    "\n",
    "##### 2. Hyperparameter Optimization\n",
    "- Use Optuna framework for Bayesian optimization\n",
    "- Search space includes:\n",
    "  - Tree structure: `n_estimators`, `max_depth`, `min_child_weight`\n",
    "  - Learning dynamics: `learning_rate`, `subsample`, `colsample_bytree`\n",
    "  - Regularization: `gamma`, `reg_alpha`, `reg_lambda`\n",
    "- 500 trials with 5-fold cross-validation\n",
    "- Maximize accuracy metric\n",
    "\n",
    "##### 3. Model Training & Evaluation\n",
    "- Train final XGBoost classifier with optimal parameters\n",
    "- Evaluate on held-out test set (20% split)\n",
    "- Visualize optimization history and hyperparameter importance\n",
    "\n",
    "#### Expected Outputs\n",
    "1. Best hyperparameters and cross-validation score\n",
    "2. Final model test accuracy\n",
    "3. Optimization history plot\n",
    "4. Hyperparameter importance visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    log_loss,\n",
    "    brier_score_loss,\n",
    ")\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.importance import get_param_importances\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Suppress Optuna logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NBA GAME PREDICTOR - FULL HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Strategy: Train on 2000-01 to 2023-24 seasons\")\n",
    "print(\"          Test on 2024-25 season (unseen data)\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading Data...\")\n",
    "df: pd.DataFrame = pd.read_csv(\"../data/csv/dataset.csv\")\n",
    "print(\"Data Loaded Successfully!\")\n",
    "\n",
    "# Convert date column to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Split into train (2000-2024) and test (2024-25 season)\n",
    "print(\"\\nSplitting data by season...\")\n",
    "train_df = df[df[\"date\"] < \"2024-10-01\"].reset_index(drop=True)\n",
    "test_df = df[df[\"date\"] >= \"2024-10-01\"].reset_index(drop=True)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} games (2000-01 to 2023-24)\")\n",
    "print(f\"Test set: {len(test_df)} games (2024-25 season)\")\n",
    "print(f\"Training date range: {train_df['date'].min()} to {train_df['date'].max()}\")\n",
    "print(f\"Test date range: {test_df['date'].min()} to {test_df['date'].max()}\")\n",
    "\n",
    "# Prepare training data\n",
    "train_df = train_df.drop([\"date\", \"home_team\", \"away_team\"], axis=1)\n",
    "X_train: pd.DataFrame = train_df.drop(\"winning_team\", axis=1)\n",
    "y_train: pd.Series = train_df[\"winning_team\"]\n",
    "\n",
    "# Prepare test data\n",
    "test_df = test_df.drop([\"date\", \"home_team\", \"away_team\"], axis=1)\n",
    "X_test: pd.DataFrame = test_df.drop(\"winning_team\", axis=1)\n",
    "y_test: pd.Series = test_df[\"winning_team\"]\n",
    "\n",
    "# Calculate class imbalance for scale_pos_weight\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight_value = class_counts[0] / class_counts[1]  # away wins / home wins\n",
    "\n",
    "print(f\"\\nTraining set distribution: {class_counts.to_dict()}\")\n",
    "print(f\"Class imbalance ratio: {scale_pos_weight_value:.3f}\")\n",
    "print(f\"Home win rate: {class_counts[0] / len(y_train) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTest set distribution: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "\n",
    "# Optuna objective - OPTIMIZED FOR NBA PREDICTION\n",
    "def objective(trial) -> float:\n",
    "    \"\"\"\n",
    "    Optuna objective function optimized for NBA game prediction.\n",
    "\n",
    "    This function is tailored for sports betting/prediction scenarios where:\n",
    "    - Probability calibration matters more than raw accuracy\n",
    "    - Natural class imbalance should be preserved (no resampling)\n",
    "    - We want well-calibrated win probabilities (e.g., 60% prediction = 60% actual)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : optuna.trial.Trial\n",
    "        Optuna trial object used to suggest hyperparameter values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Negative log loss (lower is better, but Optuna maximizes).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Uses 5-fold cross-validation on training data (2000-2024)\n",
    "    - Optimizes for log loss (probability calibration)\n",
    "    - Conservative hyperparameter ranges to prevent overfitting to noise\n",
    "    - scale_pos_weight handles class imbalance naturally\n",
    "    \"\"\"\n",
    "    params: dict[str, int | float | str] = {\n",
    "        # Tree structure - shallower for NBA (strong signals, don't need deep interactions)\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 800),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8),\n",
    "        \n",
    "        # Learning rate - log scale for better exploration\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "        \n",
    "        # Sampling - keep most data, NBA games have limited samples\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.95),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.95),\n",
    "        \n",
    "        # Regularization - conservative to prevent overfitting to fluky games\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 3),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.001, 3, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 15, log=True),\n",
    "        \n",
    "        # Min samples per leaf - higher to avoid noise\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 3, 10),\n",
    "        \n",
    "        # Handle class imbalance - search around calculated value\n",
    "        \"scale_pos_weight\": trial.suggest_float(\n",
    "            \"scale_pos_weight\", \n",
    "            scale_pos_weight_value * 0.8, \n",
    "            scale_pos_weight_value * 1.2\n",
    "        ),\n",
    "        \n",
    "        # Fixed parameters\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    model: XGBClassifier = XGBClassifier(**params)\n",
    "\n",
    "    # Use log loss for probability calibration (better for betting decisions)\n",
    "    score: np.ndarray = cross_val_score(\n",
    "        model, X_train, y_train, \n",
    "        scoring=\"neg_log_loss\",  # Negative because sklearn maximizes\n",
    "        cv=5, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    return float(np.mean(score))\n",
    "\n",
    "\n",
    "# Create and run study with pruning\n",
    "print(\"\\nStarting Optuna hyperparameter tuning...\")\n",
    "print(\"Optimizing on 2000-2024 training data (5-fold CV)...\\n\")\n",
    "\n",
    "study: optuna.Study = optuna.create_study(\n",
    "    direction=\"maximize\",  # Maximize negative log loss = minimize log loss\n",
    "    pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=10),\n",
    ")\n",
    "study.optimize(objective, n_trials=500, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "# Print best trial\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BEST TRIAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Cross-Validation Log Loss: {-study.best_trial.value:.4f}\")\n",
    "print(\"\\nOptimal Hyperparameters:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train final model with best parameters on ALL training data\n",
    "print(\"\\nTraining final model with optimal hyperparameters...\")\n",
    "print(\"Using all 2000-2024 training data...\")\n",
    "best_params: dict[str, int | float | str] = study.best_trial.params.copy()\n",
    "best_params.update(\n",
    "    {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "final_model: XGBClassifier = XGBClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on 2024-25 test set (UNSEEN DATA)\n",
    "print(\"\\nEvaluating on 2024-25 season (unseen test data)...\")\n",
    "y_pred: np.ndarray = final_model.predict(X_test)\n",
    "y_pred_proba: np.ndarray = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "test_log_loss = log_loss(y_test, y_pred_proba)\n",
    "test_brier = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "# Print comprehensive metrics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2024-25 SEASON TEST SET EVALUATION (UNSEEN DATA)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"ROC-AUC Score: {test_roc_auc:.4f}\")\n",
    "print(f\"Log Loss: {test_log_loss:.4f}\")\n",
    "print(f\"Brier Score: {test_brier:.4f} (lower is better)\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Away Win\", \"Home Win\"]))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Probability calibration analysis\n",
    "print(\"\\nProbability Calibration Analysis (2024-25 Test Set):\")\n",
    "print(\"-\" * 60)\n",
    "prob_bins = [0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for i in range(len(prob_bins) - 1):\n",
    "    mask = (y_pred_proba >= prob_bins[i]) & (y_pred_proba < prob_bins[i + 1])\n",
    "    if mask.sum() > 0:\n",
    "        actual_rate = y_test[mask].mean()\n",
    "        pred_mean = y_pred_proba[mask].mean()\n",
    "        print(f\"Predicted {prob_bins[i]:.1f}-{prob_bins[i+1]:.1f}: \"\n",
    "              f\"Actual win rate = {actual_rate:.2%} (n={mask.sum()})\")\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Visualization 1: Optimization History\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Log loss over trials\n",
    "opt_history: list[float] = [-trial.value for trial in study.trials]  # Convert to log loss\n",
    "ax1.plot(opt_history, linewidth=2, alpha=0.7)\n",
    "ax1.axhline(\n",
    "    y=-study.best_trial.value,\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Best: {-study.best_trial.value:.4f}\",\n",
    ")\n",
    "ax1.set_xlabel(\"Trial\", fontsize=14)\n",
    "ax1.set_ylabel(\"Cross-Validation Log Loss\", fontsize=14)\n",
    "ax1.set_title(\"Optuna Optimization History\", fontsize=16, fontweight=\"bold\")\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: Best value progression\n",
    "best_values = [min(opt_history[:i+1]) for i in range(len(opt_history))]\n",
    "ax2.plot(best_values, linewidth=2, alpha=0.7, color='green')\n",
    "ax2.set_xlabel(\"Trial\", fontsize=14)\n",
    "ax2.set_ylabel(\"Best Log Loss So Far\", fontsize=14)\n",
    "ax2.set_title(\"Best Value Progression\", fontsize=16, fontweight=\"bold\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"optimization_history.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Hyperparameter Importance\n",
    "param_importance: dict[str, float] = get_param_importances(study)\n",
    "params: list[str] = list(param_importance.keys())\n",
    "importances: list[float] = list(param_importance.values())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(params, importances, color=\"steelblue\", alpha=0.8)\n",
    "plt.xlabel(\"Importance\", fontsize=14)\n",
    "plt.ylabel(\"Hyperparameters\", fontsize=14)\n",
    "plt.title(\"Hyperparameter Importance\", fontsize=16, fontweight=\"bold\")\n",
    "plt.grid(True, alpha=0.3, axis=\"x\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"hyperparameter_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Confusion Matrix\n",
    "cm: np.ndarray = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Away Win\", \"Home Win\"],\n",
    "    yticklabels=[\"Away Win\", \"Home Win\"],\n",
    "    cbar_kws={\"label\": \"Count\"},\n",
    ")\n",
    "plt.title(\"Confusion Matrix (2024-25 Test Season)\", fontsize=16, fontweight=\"bold\")\n",
    "plt.ylabel(\"True Label\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 4: ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (AUC = {test_roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\", label=\"Random Classifier\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "plt.title(\"ROC Curve (2024-25 Test Season)\", fontsize=16, fontweight=\"bold\")\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_curve.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 5: Calibration Curve (Critical for betting!)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate calibration curve\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_test, y_pred_proba, n_bins=10, strategy='uniform'\n",
    ")\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", \n",
    "         label=f\"XGBoost (Brier: {test_brier:.4f})\", linewidth=2, markersize=8)\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect Calibration\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Mean Predicted Probability\", fontsize=14)\n",
    "plt.ylabel(\"Fraction of Positives (Actual)\", fontsize=14)\n",
    "plt.title(\"Probability Calibration Curve (2024-25 Test)\", fontsize=16, fontweight=\"bold\")\n",
    "plt.legend(loc=\"upper left\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"calibration_curve.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 6: Feature Importance\n",
    "feature_importance: np.ndarray = final_model.feature_importances_\n",
    "feature_names: pd.Index = X_train.columns\n",
    "\n",
    "# Get top 20 features\n",
    "indices: np.ndarray = np.argsort(feature_importance)[::-1][:20]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.barh(\n",
    "    range(len(indices)),\n",
    "    feature_importance[indices],\n",
    "    color=\"teal\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Feature Importance\", fontsize=14)\n",
    "plt.ylabel(\"Features\", fontsize=14)\n",
    "plt.title(\"Top 20 Most Important Features\", fontsize=16, fontweight=\"bold\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis=\"x\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 7: Prediction Confidence Distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram of all predictions\n",
    "ax1.hist(y_pred_proba, bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax1.axvline(0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "ax1.set_xlabel(\"Predicted Probability (Home Win)\", fontsize=14)\n",
    "ax1.set_ylabel(\"Frequency\", fontsize=14)\n",
    "ax1.set_title(\"Distribution of Predicted Probabilities\", fontsize=16, fontweight=\"bold\")\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Separate by correct/incorrect predictions\n",
    "correct_mask = (y_pred == y_test)\n",
    "ax2.hist(y_pred_proba[correct_mask], bins=30, alpha=0.7, \n",
    "         color='green', label='Correct Predictions', edgecolor='black')\n",
    "ax2.hist(y_pred_proba[~correct_mask], bins=30, alpha=0.7, \n",
    "         color='red', label='Incorrect Predictions', edgecolor='black')\n",
    "ax2.axvline(0.5, color='black', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel(\"Predicted Probability (Home Win)\", fontsize=14)\n",
    "ax2.set_ylabel(\"Frequency\", fontsize=14)\n",
    "ax2.set_title(\"Prediction Confidence: Correct vs Incorrect\", fontsize=16, fontweight=\"bold\")\n",
    "ax2.legend(fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prediction_confidence.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll visualizations saved successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHTS FOR NBA BETTING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"• Model trained on 24 years (2000-2024): {len(X_train)} games\")\n",
    "print(f\"• Test accuracy on 2024-25 season: {test_accuracy*100:.1f}%\")\n",
    "print(f\"• ROC-AUC of {test_roc_auc:.3f} shows ranking ability\")\n",
    "print(f\"• Brier score of {test_brier:.4f} indicates probability calibration\")\n",
    "print(f\"  (Lower Brier = better calibrated probabilities)\")\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"• This model is now ready for 2025-26 predictions\")\n",
    "print(f\"• Monitor calibration - your probabilities should match reality\")\n",
    "print(f\"• For betting: focus on games with 60%+ confidence\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n✓ Pipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
