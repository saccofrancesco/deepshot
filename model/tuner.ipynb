{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "In this section, we will set up the necessary environment for training optimizing a machine learning model using a XGBoost Classifier classifier and **Bayesian Search**. We will:\n",
    "\n",
    "1. **Import Essential Libraries** – Load key Python libraries for data handling, model training, evaluation, and hyperparameter tuning.\n",
    "2. **Load and Prepare the Dataset** – Read the dataset from a CSV file, remove unnecessary columns, and split the data into features (`X`) and target labels (`y`).\n",
    "3. **Perform Data Splitting** – Divide the dataset into training and testing sets to ensure the model generalizes well to unseen data.\n",
    "4. **Define the Hyperparameter Search Space** – Specify a range of values for key hyperparameters of the Random Forest model to optimize performance.\n",
    "5. **Optimize Model with Bayesian Search** – Utilize Bayesian optimization via `BayesSearchCV` to efficiently search for the best hyperparameters.\n",
    "6. **Evaluate the Model** – Assess the model's performance using accuracy and a classification report.\n",
    "\n",
    "The entire process will be logged with **Rich Console** to enhance readability and provide real-time updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from rich.console import Console\n",
    "import numpy as np\n",
    "\n",
    "# Initialize rich console\n",
    "console: Console = Console()\n",
    "\n",
    "# Load dataset\n",
    "with console.status(\"[green]Loading Data...\") as status:\n",
    "    df: pd.DataFrame = pd.read_csv(\"../data/csv/dataset.csv\")\n",
    "    status.update(\"Data Loaded Successfully!\")\n",
    "\n",
    "# Drop non-training columns\n",
    "df: pd.DataFrame = df.drop([\"date\", \"home_team\", \"away_team\"], axis=1)\n",
    "X: pd.DataFrame = df.drop(\"winning_team\", axis=1)\n",
    "y: pd.DataFrame = df[\"winning_team\"]\n",
    "\n",
    "# Split dataset\n",
    "console.print(\n",
    "    \"Splitting the dataset into training and testing sets...\", style=\"bold cyan\"\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_space: dict[str, Integer | Real | Categorical] = {\n",
    "    \"n_estimators\": Integer(100, 1000),  # Number of boosting rounds\n",
    "    \"max_depth\": Integer(3, 15),  # Depth of trees\n",
    "    \"learning_rate\": Real(0.01, 0.3, prior=\"log-uniform\"),  # Step size shrinkage\n",
    "    \"subsample\": Real(0.5, 1.0),  # Fraction of samples for training each tree\n",
    "    \"colsample_bytree\": Real(0.5, 1.0),  # Fraction of features for each tree\n",
    "    \"gamma\": Real(0, 5),  # Minimum loss reduction for further partition\n",
    "    \"reg_alpha\": Real(0, 10),  # L1 regularization term on weights\n",
    "    \"reg_lambda\": Real(0, 10),  # L2 regularization term on weights\n",
    "    \"min_child_weight\": Integer(1, 10),  # Minimum sum of instance weight in a child\n",
    "    \"objective\": Categorical([\"binary:logistic\"]),  # Binary classification\n",
    "    \"eval_metric\": Categorical([\"logloss\", \"auc\", \"error\"]),  # Log loss as evaluation metric\n",
    "}\n",
    "\n",
    "# Bayesian optimization\n",
    "console.print(\"Starting Bayesian Hyperparameter Tuning...\", style=\"bold yellow\")\n",
    "bayes_search: BayesSearchCV = BayesSearchCV(\n",
    "    XGBClassifier(random_state=42),\n",
    "    param_space,\n",
    "    n_iter=30,  # Number of evaluations\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "with console.status(\n",
    "    \"[yellow]Optimizing hyperparameters... please wait.[/yellow]\"\n",
    ") as status:\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "    status.update(\"[green]Hyperparameter tuning complete![/green]\")\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_params: dict[str, int | float | str] = bayes_search.best_params_\n",
    "best_model: XGBClassifier = bayes_search.best_estimator_\n",
    "console.print(\"Best Hyperparameters:\", best_params, style=\"bold green\")\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred: np.ndarray = best_model.predict(X_test)\n",
    "accuracy: float = accuracy_score(y_test, y_pred)\n",
    "console.print(\n",
    "    f\"\\n[bold green]Best Model Accuracy: {accuracy * 100:.2f}%[/bold green]\",\n",
    "    style=\"bold\",\n",
    ")\n",
    "console.print(\n",
    "    \"\\n[bold magenta]Classification Report:[/bold magenta]\",\n",
    "    classification_report(y_test, y_pred),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
