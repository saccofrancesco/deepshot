{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with Optuna Hyperparameter Tuning\n",
    "\n",
    "#### Overview\n",
    "This notebook implements a machine learning pipeline to predict NBA game outcomes using XGBoost with automated hyperparameter optimization via Optuna.\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "##### 1. Data Preparation\n",
    "- Load NBA game dataset from CSV\n",
    "- Filter games from October 19, 2021 onwards\n",
    "- Remove non-predictive features (date, team names)\n",
    "- Separate features (X) and target variable (winning_team)\n",
    "\n",
    "##### 2. Hyperparameter Optimization\n",
    "- Use Optuna framework for Bayesian optimization\n",
    "- Search space includes:\n",
    "  - Tree structure: `n_estimators`, `max_depth`, `min_child_weight`\n",
    "  - Learning dynamics: `learning_rate`, `subsample`, `colsample_bytree`\n",
    "  - Regularization: `gamma`, `reg_alpha`, `reg_lambda`\n",
    "- 500 trials with 5-fold cross-validation\n",
    "- Maximize accuracy metric\n",
    "\n",
    "##### 3. Model Training & Evaluation\n",
    "- Train final XGBoost classifier with optimal parameters\n",
    "- Evaluate on held-out test set (20% split)\n",
    "- Visualize optimization history and hyperparameter importance\n",
    "\n",
    "#### Expected Outputs\n",
    "1. Best hyperparameters and cross-validation score\n",
    "2. Final model test accuracy\n",
    "3. Optimization history plot\n",
    "4. Hyperparameter importance visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# XGBoost classifier for probability prediction\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,                 # Overall prediction accuracy\n",
    "    classification_report,          # Precision, recall, F1 per class\n",
    "    roc_auc_score,                  # Discrimination power\n",
    "    log_loss,                       # Negative log likelihood (calibration metric)\n",
    "    brier_score_loss,               # Squared error of predicted probabilities\n",
    ")\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "# Optuna tools for hyperparameter optimization\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Suppress verbose Optuna logging for cleaner output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Load historical NBA game dataset\n",
    "print(\"Loading Data...\")\n",
    "df: pd.DataFrame = pd.read_csv(\"../data/csv/dataset.csv\")\n",
    "print(\"Data Loaded Successfully!\")\n",
    "\n",
    "# Convert the 'date' column to datetime objects for time-based splits\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Training data: all games before October 1, 2024\n",
    "print(\"\\nSplitting data by season...\")\n",
    "train_df: pd.DataFrame = df[df[\"date\"] < \"2024-10-01\"].reset_index(drop=True)\n",
    "\n",
    "# Test data: games from 2024-25 season (unseen during training)\n",
    "test_df: pd.DataFrame = df[df[\"date\"] >= \"2024-10-01\"].reset_index(drop=True)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} games\")\n",
    "print(f\"Test set: {len(test_df)} games\")\n",
    "\n",
    "# Columns not used for model training\n",
    "drop_cols: list[str] = [\"date\", \"home_team\", \"away_team\"]\n",
    "\n",
    "# Remove non-feature columns\n",
    "train_df: pd.DataFrame = train_df.drop(drop_cols, axis=1)\n",
    "test_df: pd.DataFrame = test_df.drop(drop_cols, axis=1)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X_train: pd.DataFrame = train_df.drop(\"winning_team\", axis=1)\n",
    "y_train: pd.Series = train_df[\"winning_team\"]\n",
    "X_test: pd.DataFrame = test_df.drop(\"winning_team\", axis=1)\n",
    "y_test: pd.Series = test_df[\"winning_team\"]\n",
    "\n",
    "# Check class imbalance to guide XGBoost's scale_pos_weight\n",
    "imbalance_ratio: float = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\nClass imbalance ratio (Home:Away) â‰ˆ {imbalance_ratio:.2f}\")\n",
    "\n",
    "# Define the Optuna Objective function on which the optimization will happen\n",
    "def objective(trial) -> float:\n",
    "    \"\"\"\n",
    "    Defines the objective function for Optuna hyperparameter optimization.\n",
    "    Optimizes negative log loss (probability calibration) for NBA game outcomes.\n",
    "    \n",
    "    Parameters:\n",
    "        trial: Optuna trial object for suggesting hyperparameter values.\n",
    "\n",
    "    Returns:\n",
    "        Mean 5-fold cross-validated negative log loss.\n",
    "    \"\"\"\n",
    "    params: dict[str, int | float | str] = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 900),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.95),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.95),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-4, 10, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 20, log=True),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 15),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 5.0),\n",
    "\n",
    "        # Fixed parameters\n",
    "        \"objective\": \"binary:logistic\",     # Predict probabilities for binary outcome\n",
    "        \"eval_metric\": \"logloss\",           # Optimize log loss\n",
    "        \"random_state\": 42,                 # Reproducibility\n",
    "        \"n_jobs\": -1,                       # Use all CPU cores\n",
    "    }\n",
    "\n",
    "    model: XGBClassifier = XGBClassifier(**params)\n",
    "\n",
    "    # 5-fold cross-validation on **real data** (no resampling)\n",
    "    # Scoring uses negative log loss because Optuna maximizes the objective\n",
    "    score: float = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring=\"neg_log_loss\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Return mean CV score\n",
    "    return float(np.mean(score))\n",
    "\n",
    "\n",
    "# Run Optuna tuning\n",
    "print(\"\\nStarting Optuna tuning...\\n\")\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",                                           # Maximize neg_log_loss = minimize log loss\n",
    "    sampler=TPESampler(n_startup_trials=20, seed=42),               # Bayesian TPE sampler\n",
    "    pruner=MedianPruner(n_startup_trials=10, n_warmup_steps=20),    # Early stopping for unpromising trials\n",
    ")\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=400,               # Maximum number of trials\n",
    "    timeout=10800,              # 3 hours max\n",
    "    n_jobs=-1,                  # Parallel evaluation\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "# Training the final model\n",
    "print(\"\\nBEST TRIAL:\")\n",
    "print(f\"Best CV Log Loss: {-study.best_trial.value:.4f}\")\n",
    "best_params = study.best_trial.params.copy()\n",
    "best_params.update(\n",
    "    {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    ")\n",
    "base_model: XGBClassifier = XGBClassifier(**best_params)\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "# Calibrate the probabilities\n",
    "print(\"\\nCalibrating probabilities...\")\n",
    "calibrated_model: CalibratedClassifierCV = CalibratedClassifierCV(\n",
    "    base_model,\n",
    "    method=\"isotonic\",  # best for larger datasets\n",
    "    cv=5,\n",
    ")\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the calibrated model on the test set selected at the start of the pipeline\n",
    "y_pred: list[int] = calibrated_model.predict(X_test)\n",
    "y_pred_proba: list[tuple[float, float]] = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "test_accuracy: float = accuracy_score(y_test, y_pred)\n",
    "test_roc_auc: float = roc_auc_score(y_test, y_pred_proba)\n",
    "test_log_loss: float = log_loss(y_test, y_pred_proba)\n",
    "test_brier: float = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "# Calibration analysis\n",
    "print(\"\\nTEST SET RESULTS (2024-25):\")\n",
    "print(f\"Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"ROC-AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"Log Loss: {test_log_loss:.4f}\")\n",
    "print(f\"Brier Score: {test_brier:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nCalibration by bins:\")\n",
    "prob_bins: list[float] = [0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for i in range(len(prob_bins) - 1):\n",
    "    mask = (y_pred_proba >= prob_bins[i]) & (y_pred_proba < prob_bins[i + 1])\n",
    "    if mask.sum() > 0:\n",
    "        actual_rate = y_test[mask].mean()\n",
    "        print(\n",
    "            f\"Predicted {prob_bins[i]:.1f}-{prob_bins[i+1]:.1f}: \"\n",
    "            f\"Actual away win rate = {actual_rate:.2%} (n={mask.sum()})\"\n",
    "        )\n",
    "\n",
    "# Visualize the calibration plot to identify the strenght and weakneses\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "# Calibration Curve\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_test, y_pred_proba, n_bins=10, strategy=\"uniform\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "         label=f\"XGBoost (Brier: {test_brier:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect Calibration\")\n",
    "plt.xlabel(\"Mean Predicted Probability\")\n",
    "plt.ylabel(\"Fraction of Positives\")\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
