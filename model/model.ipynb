{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation Workflow\n",
    "\n",
    "In this section, we will go through the entire process of training and evaluating a machine learning model for predicting NBA game outcomes. Below is an overview of the steps taken:\n",
    "\n",
    "##### 1. **Removing Any Existing Model File**\n",
    "Before training a new model, we ensure that any previously saved model file (`deepshot.pkl`) is deleted to prevent conflicts when saving the updated version.\n",
    "\n",
    "##### 2. **Loading the Dataset**\n",
    "We use `pandas` to load the dataset from a CSV file. A loading spinner is displayed using `rich` to provide visual feedback while the data is being read.\n",
    "\n",
    "##### 3. **Preprocessing the Data**\n",
    "- We drop unnecessary columns, such as `home_team` and `away_team`, since they are not used as input features for training.\n",
    "- Any additional irrelevant statistical features (if specified) are also removed to optimize model performance.\n",
    "\n",
    "##### 4. **Defining Features and Target Variable**\n",
    "- The feature matrix `X` consists of all columns except the `winning_team` column.\n",
    "- The target variable `y` is set as `winning_team`, which is already encoded as `0` (home win) and `1` (away win).\n",
    "\n",
    "##### 5. **Splitting the Dataset**\n",
    "The dataset is split into training and testing sets using an 80-20 ratio to evaluate model performance effectively.\n",
    "\n",
    "##### 6. **Training the Model**\n",
    "- A `XGBoostClassifier` is initialized with specific hyperparameters to improve model performance.\n",
    "- A progress spinner is displayed while the model is being trained.\n",
    "\n",
    "##### 7. **Evaluating the Model**\n",
    "- Predictions are made on the test set.\n",
    "- The model's accuracy is calculated and displayed using `rich` for better readability.\n",
    "- A classification report is printed to show precision, recall, and F1-score for each class.\n",
    "\n",
    "##### 8. **Saving the Model**\n",
    "Finally, the trained model is saved as `deepshot.pkl` using `joblib` for future use.\n",
    "\n",
    "This structured approach ensures that the model is trained, evaluated, and saved efficiently, with informative feedback at each step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "from rich.console import Console\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Removing the already existing model to overwrite it with the new one\n",
    "try:\n",
    "    os.remove(\"deepshot.pkl\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialize rich console for pretty printing\n",
    "console: Console = Console()\n",
    "\n",
    "# Start spinner for data loading\n",
    "with console.status(\"[green]Loading Data...\") as status:\n",
    "    # Load CSV Data\n",
    "    df: pd.DataFrame = pd.read_csv(\"../data/csv/dataset.csv\")\n",
    "    status.update(\"Data Loaded Successfully!\")\n",
    "\n",
    "# Drop columns that are not used for training (just home_team and away_team)\n",
    "df: pd.DataFrame = df.drop([\"date\", \"home_team\", \"away_team\"], axis=1)\n",
    "\n",
    "# Drop irrelvant stats columns\n",
    "stats_to_drop: list[str] = []\n",
    "for stat in stats_to_drop:\n",
    "    df: pd.DataFrame = df.drop([f\"home_{stat}\", f\"away_{stat}\"], axis=1)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X: pd.DataFrame = df.drop(\n",
    "    \"winning_team\", axis=1\n",
    ")  # Features (all columns except 'winning_team')\n",
    "y: pd.Series = df[\"winning_team\"]  # Target variable (already 0 or 1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "console.print(\n",
    "    \"Splitting the dataset into training and testing sets...\", style=\"bold cyan\"\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train the Random Forest model with a progress bar\n",
    "with console.status(\"[yellow]Training model... please wait.[/yellow]\") as status:\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    xgb: XGBClassifier = XGBClassifier(\n",
    "        colsample_bytree=0.5,\n",
    "        eval_metric=\"logloss\",\n",
    "        gamma=0.0,\n",
    "        learning_rate=0.03580307297615659,\n",
    "        max_depth=3,\n",
    "        min_child_weight=4,\n",
    "        n_estimators=1000,\n",
    "        objective=\"binary:logistic\",\n",
    "        reg_alpha=10.0,\n",
    "        reg_lambda=10.0,\n",
    "        subsample=0.8651456011642156,\n",
    "        random_state=42,\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    status.update(\"[green]Model training complete![/green]\")  # Update status once done\n",
    "\n",
    "# Evaluate the model\n",
    "console.print(\"Evaluating the model...\", style=\"bold cyan\")\n",
    "y_pred: np.ndarray = xgb.predict(X_test)\n",
    "accuracy: float = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy with rich styling\n",
    "console.print(\n",
    "    f\"\\n[bold green]Model Accuracy: {accuracy * 100:.2f}%[/bold green]\", style=\"bold\"\n",
    ")\n",
    "\n",
    "# Print detailed classification results with rich\n",
    "console.print(\"\\n[bold magenta]Classification Report:[/bold magenta]\", style=\"bold\")\n",
    "console.print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(xgb, \"deepshot.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Analyzing the Model  \n",
    "\n",
    "In this section, we load a pre-trained Random Forest model (`deepshot.pkl`) using `joblib`.  \n",
    "We then configure Pandas display options to ensure that all columns and rows are fully visible in the output.  \n",
    "\n",
    "Once the model is loaded, we extract and analyze feature importances to understand which factors contribute most to the predictions.  \n",
    "The feature importance values are obtained from the model and combined with feature names into a Pandas DataFrame.  \n",
    "\n",
    "Finally, we sort the features in descending order of importance and display the results using `console.print` for better readability.  \n",
    "Afterward, we reset Pandas display options to their default values to avoid affecting subsequent outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import joblib\n",
    "import pandas\n",
    "from xgboost import XGBClassifier\n",
    "from rich.console import Console\n",
    "import numpy as np\n",
    "\n",
    "# Initialize rich console for pretty printing\n",
    "console: Console = Console()\n",
    "\n",
    "# Loading the model\n",
    "xgb: XGBClassifier = joblib.load(\"deepshot.pkl\")\n",
    "\n",
    "# Load CSV Data\n",
    "df: pandas.DataFrame = pandas.read_csv(\"../data/csv/dataset.csv\")\n",
    "\n",
    "# Drop columns that are not used for training (just home_team and away_team)\n",
    "df: pandas.DataFrame = df.drop([\"date\", \"home_team\", \"away_team\"], axis=1)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X: pandas.DataFrame = df.drop(\n",
    "    \"winning_team\", axis=1\n",
    ")  # Features (all columns except 'winning_team')\n",
    "y: pandas.Series = df[\"winning_team\"]  # Target variable (already 0 or 1)\n",
    "\n",
    "# Set options to display all columns\n",
    "pandas.set_option(\"display.max_columns\", None)  # No column truncation\n",
    "pandas.set_option(\"display.width\", None)  # Automatically adjust width\n",
    "pandas.set_option(\"display.max_rows\", None)  # Show all rows, if necessary\n",
    "\n",
    "# Now print the feature importance DataFrame\n",
    "console.print(\"\\n[bold yellow]Feature Importances:[/bold yellow]\", style=\"bold\")\n",
    "feature_importances: np.ndarray = xgb.feature_importances_\n",
    "features: pandas.core.indexes.base.Index = X.columns  # Get the feature names\n",
    "\n",
    "# Create a DataFrame to visualize feature importance\n",
    "importance_df: pandas.DataFrame = pandas.DataFrame({\"Feature\": features, \"Importance\": feature_importances})\n",
    "\n",
    "# Sort by importance in descending order\n",
    "importance_df: pandas.DataFrame = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "console.print(importance_df)\n",
    "\n",
    "# Reset Pandas display options to default (optional)\n",
    "pandas.reset_option(\"display.max_columns\")\n",
    "pandas.reset_option(\"display.width\")\n",
    "pandas.reset_option(\"display.max_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading and Feature Importance Analysis\n",
    "\n",
    "In this section, we load a pre-trained machine learning model and prepare the dataset for evaluation. The steps are as follows:\n",
    "\n",
    "1. **Load the Model:** We use `joblib` to load a previously trained model (`deepshot.pkl`).\n",
    "2. **Load and Preprocess Data:** The dataset is read from a CSV file. Since some columns like `home_team` and `away_team` are not used for training, we drop them.\n",
    "3. **Define Features and Target Variable:**\n",
    "   - `X`: Contains all feature columns except the target variable (`winning_team`).\n",
    "   - `y`: The target variable, which indicates whether the home team won (0) or the away team won (1).\n",
    "4. **Split Data for Testing:** We split the dataset into training and testing sets using an 80/20 ratio.\n",
    "5. **Feature Importance Analysis with SHAP:**\n",
    "   - A sample of 250 test instances is selected.\n",
    "   - SHAP (SHapley Additive exPlanations) values are computed using a TreeExplainer.\n",
    "   - The feature importance is visualized using a SHAP summary plot to understand how different features influence the model’s predictions.\n",
    "\n",
    "This analysis helps us interpret the model’s decision-making process and identify the most influential factors in predicting game outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "\n",
    "\n",
    "# Loading the model\n",
    "xgb: XGBClassifier = joblib.load(\"deepshot.pkl\")\n",
    "\n",
    "# Load CSV Data\n",
    "df: pandas.DataFrame = pandas.read_csv(\"../data/csv/dataset.csv\")\n",
    "\n",
    "# Drop columns that are not used for training (just home_team and away_team)\n",
    "df: pandas.DataFrame = df.drop([\"date\", \"home_team\", \"away_team\"], axis=1)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X: pandas.DataFrame = df.drop(\n",
    "    \"winning_team\", axis=1\n",
    ")  # Features (all columns except 'winning_team')\n",
    "y: pandas.Series = df[\"winning_team\"]  # Target variable (already 0 or 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Analyzing feature importance with SHAP values and chart\n",
    "sample: pandas.core.frame.DataFrame = X_test.sample(1000, random_state=42)\n",
    "explainer: shap.explainers._tree.TreeExplainer = shap.TreeExplainer(xgb, sample)\n",
    "shap_values: shap._explanation.Explanation = explainer(sample)\n",
    "shap.summary_plot(shap_values, sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
